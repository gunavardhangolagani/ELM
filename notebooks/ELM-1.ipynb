{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNfcPxg8zqwm"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMaz6hddzqwp",
        "outputId": "5191cc21-a2c4-4e38-b1f2-d52f0cbbbe57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hpelm\n",
            "  Downloading hpelm-1.0.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fasteners (from hpelm)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting nose (from hpelm)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hpelm) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.12 in /usr/local/lib/python3.11/dist-packages (from hpelm) (1.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hpelm) (1.17.0)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.11/dist-packages (from hpelm) (3.10.2)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.11/dist-packages (from tables->hpelm) (2.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tables->hpelm) (24.2)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from tables->hpelm) (9.0.0)\n",
            "Requirement already satisfied: blosc2>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from tables->hpelm) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from tables->hpelm) (4.12.2)\n",
            "Requirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->hpelm) (1.9.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->hpelm) (1.1.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->hpelm) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->blosc2>=2.3.0->tables->hpelm) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->blosc2>=2.3.0->tables->hpelm) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->blosc2>=2.3.0->tables->hpelm) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->blosc2>=2.3.0->tables->hpelm) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->blosc2>=2.3.0->tables->hpelm) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->blosc2>=2.3.0->tables->hpelm) (1.3.1)\n",
            "Downloading hpelm-1.0.10-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nose, fasteners, hpelm\n",
            "Successfully installed fasteners-0.19 hpelm-1.0.10 nose-1.3.7\n"
          ]
        }
      ],
      "source": [
        "! pip install hpelm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "2SZO4dD2zqwq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import hpelm  # Importing HPELM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwF7YZP7zqwq"
      },
      "source": [
        "#### Load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRXtn7HTzqwr"
      },
      "outputs": [],
      "source": [
        "data = load_digits()\n",
        "X, y = data.data, data.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R0sz0c2zqwr"
      },
      "source": [
        "## Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the target\n",
        "ohe = OneHotEncoder(sparse_output=False)\n",
        "y_onehot = ohe.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "# Split dataset into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "BD66Helq0n4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlBFNT0Jzqwr"
      },
      "source": [
        "## ELM-model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "3Cz4-OBjzqws"
      },
      "outputs": [],
      "source": [
        "class ELM:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.W = np.random.randn(self.hidden_size, self.input_size)  # Random weights\n",
        "        self.b = np.random.randn(self.hidden_size, 1)  # Random bias\n",
        "\n",
        "    def _hidden_layer_output(self, X):\n",
        "        return np.tanh(np.dot(self.W, X.T) + self.b)\n",
        "\n",
        "    def train(self, X, Y):\n",
        "        H = self._hidden_layer_output(X)\n",
        "        H_T = H.T\n",
        "        self.beta = np.dot(np.linalg.pinv(H_T), Y)  # Moore-Penrose Pseudo-inverse\n",
        "\n",
        "    def predict(self, X):\n",
        "        H = self._hidden_layer_output(X)\n",
        "        return np.dot(H.T, self.beta)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpbUimIPzqws"
      },
      "source": [
        "### Custom model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxWLh2cgzqws"
      },
      "source": [
        "#### Train Custom ELM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqqbtKsqzqws"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "elm = ELM(input_size=X_train.shape[1], hidden_size=100, output_size=y_train.shape[1])\n",
        "elm.train(X_train, y_train)\n",
        "custom_elm_time = time.time() - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kimRuictzqws"
      },
      "source": [
        "#### Predict using Custom ELM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2EDN-odzqws"
      },
      "outputs": [],
      "source": [
        "y_pred_custom = elm.predict(X_test)\n",
        "y_pred_labels_custom = np.argmax(y_pred_custom, axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEgc4LcKzqws"
      },
      "source": [
        "#### Evaluate Custom ELM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Is7NkfDzqwt"
      },
      "outputs": [],
      "source": [
        "custom_elm_acc = accuracy_score(y_test_labels, y_pred_labels_custom)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwaYwNw7zqwt"
      },
      "source": [
        "### HPELM-(Hierarchical ELM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYQDRQkJzqwt"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "hp_elm = hpelm.ELM(X_train.shape[1], y_train.shape[1])\n",
        "hp_elm.add_neurons(100, \"tanh\")\n",
        "hp_elm.train(X_train, y_train, \"c\")\n",
        "hpelm_time = time.time() - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW7Oixtlzqwt"
      },
      "source": [
        "#### Predict using HPELM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yf2VjMtXzqwt"
      },
      "outputs": [],
      "source": [
        "y_pred_hpelm = hp_elm.predict(X_test)\n",
        "y_pred_labels_hpelm = np.argmax(y_pred_hpelm, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5FBQaSrzqwt"
      },
      "source": [
        "#### Evaluate HPELM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ejMBC1wzqwt"
      },
      "outputs": [],
      "source": [
        "hpelm_acc = accuracy_score(y_test_labels, y_pred_labels_hpelm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyuWPQ-Gzqwt"
      },
      "source": [
        "## Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZhu__oczqwt",
        "outputId": "9a388227-f98b-47b3-c2e8-052c392d96ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom ELM Accuracy: 0.9277777777777778\n",
            "HPELM Accuracy: 0.9222222222222223\n",
            "Custom ELM Training Time: 0.09097146987915039\n",
            "HPELM Training Time: 0.11864566802978516\n",
            "Classification Report (Custom ELM):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94        33\n",
            "           1       0.96      0.93      0.95        28\n",
            "           2       0.92      1.00      0.96        33\n",
            "           3       0.94      0.94      0.94        34\n",
            "           4       1.00      0.93      0.97        46\n",
            "           5       0.90      0.96      0.93        47\n",
            "           6       1.00      0.94      0.97        35\n",
            "           7       0.89      0.91      0.90        34\n",
            "           8       0.89      0.80      0.84        30\n",
            "           9       0.88      0.88      0.88        40\n",
            "\n",
            "    accuracy                           0.93       360\n",
            "   macro avg       0.93      0.93      0.93       360\n",
            "weighted avg       0.93      0.93      0.93       360\n",
            "\n",
            "Classification Report (HPELM):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.95        33\n",
            "           1       0.93      0.89      0.91        28\n",
            "           2       0.89      0.94      0.91        33\n",
            "           3       0.91      0.85      0.88        34\n",
            "           4       0.96      1.00      0.98        46\n",
            "           5       0.93      0.91      0.92        47\n",
            "           6       0.92      0.97      0.94        35\n",
            "           7       1.00      0.97      0.99        34\n",
            "           8       0.93      0.83      0.88        30\n",
            "           9       0.81      0.88      0.84        40\n",
            "\n",
            "    accuracy                           0.92       360\n",
            "   macro avg       0.92      0.92      0.92       360\n",
            "weighted avg       0.92      0.92      0.92       360\n",
            "\n",
            "Confusion Matrix (Custom ELM):\n",
            " [[32  0  0  0  0  0  0  0  0  1]\n",
            " [ 0 26  1  0  0  0  0  0  1  0]\n",
            " [ 0  0 33  0  0  0  0  0  0  0]\n",
            " [ 0  0  1 32  0  0  0  0  1  0]\n",
            " [ 2  0  0  0 43  0  0  1  0  0]\n",
            " [ 0  0  0  0  0 45  0  0  0  2]\n",
            " [ 0  0  1  0  0  0 33  0  1  0]\n",
            " [ 0  0  0  0  0  2  0 31  0  1]\n",
            " [ 0  1  0  1  0  1  0  2 24  1]\n",
            " [ 1  0  0  1  0  2  0  1  0 35]]\n",
            "Confusion Matrix (HPELM):\n",
            " [[31  0  0  1  0  0  1  0  0  0]\n",
            " [ 0 25  2  0  0  0  0  0  0  1]\n",
            " [ 0  0 31  1  0  0  1  0  0  0]\n",
            " [ 0  0  1 29  0  1  0  0  1  2]\n",
            " [ 0  0  0  0 46  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 43  1  0  0  3]\n",
            " [ 1  0  0  0  0  0 34  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 33  0  1]\n",
            " [ 0  1  1  0  1  1  0  0 25  1]\n",
            " [ 0  1  0  1  1  1  0  0  1 35]]\n"
          ]
        }
      ],
      "source": [
        "# ---------------- Comparison Summary ---------------- #\n",
        "print(\"Custom ELM Accuracy:\", custom_elm_acc)\n",
        "print(\"HPELM Accuracy:\", hpelm_acc)\n",
        "print(\"Custom ELM Training Time:\", custom_elm_time)\n",
        "print(\"HPELM Training Time:\", hpelm_time)\n",
        "print(\"Classification Report (Custom ELM):\\n\", classification_report(y_test_labels, y_pred_labels_custom))\n",
        "print(\"Classification Report (HPELM):\\n\", classification_report(y_test_labels, y_pred_labels_hpelm))\n",
        "print(\"Confusion Matrix (Custom ELM):\\n\", confusion_matrix(y_test_labels, y_pred_labels_custom))\n",
        "print(\"Confusion Matrix (HPELM):\\n\", confusion_matrix(y_test_labels, y_pred_labels_hpelm))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtUBavf1zqwt"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}